{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Terms of Service / Privacy Policy Classification Tool\n",
    "\n",
    "Instructions..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import requests\n",
    "from readability import Document\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('topics', header = 'infer')\n",
    "data = pd.read_csv('classes', header = 'infer')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = RegexpTokenizer(r'\\w+')\n",
    "data['tokens'] = data['quoteText'].apply(tokenizer.tokenize)\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def lemmatize_block(cell):\n",
    "    lemma_words = []\n",
    "    for word in cell:\n",
    "        lemma_words.append(lemmatizer.lemmatize((word.lower())))\n",
    "    return \" \".join(lemma_words)\n",
    "\n",
    "data['lemmatized'] = data.tokens.apply(lemmatize_block)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[['lemmatized']]\n",
    "y = data['topics']\n",
    "X_class = ratingdf[['lemmatized']]\n",
    "y_class = ratingdf['point_other']\n",
    "\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfidf.fit(X['lemmatized'])\n",
    "X_tfidf = tfidf.transform(X['lemmatized'])\n",
    "\n",
    "tfidf_class = TfidfVectorizer(stop_words='english')\n",
    "tfidf_class.fit(X_class['lemmatized'])\n",
    "X_tfidf_class = tfidf_class.transform(X_class['lemmatized'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=100.0, class_weight='balanced', dual=False,\n",
       "          fit_intercept=True, intercept_scaling=1, max_iter=100,\n",
       "          multi_class='multinomial', n_jobs=None, penalty='l2',\n",
       "          random_state=7, solver='newton-cg', tol=0.0001, verbose=0,\n",
       "          warm_start=False)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgdc_binary = SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
    "       early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
    "       l1_ratio=0.15, learning_rate='optimal', loss='log', max_iter=1000,\n",
    "       n_iter=None, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
    "       power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
    "       validation_fraction=0.1, verbose=0, warm_start=False)\n",
    "sgdc_binary.fit(X_tfidf_class, y_class)\n",
    "\n",
    "lr_tfidf = LogisticRegression(C=100.0, class_weight='balanced', solver='newton-cg', multi_class='multinomial',\n",
    "                          random_state=7)\n",
    "lr_tfidf.fit(X_tfidf, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dd = {'Waiving your right': 'You might be giving up some of your consumer or legal rights',\n",
    "      'Business Transfers': 'Your data might be a transferable business asset',\n",
    "     'Changes to Terms': 'You may not be notified in the event of changes, or those changes might be unfavourable',\n",
    "     'Anonymity and Tracking':'The service may be tracking you in unexpected ways',\n",
    "      'Content':'If the service allows you to upload content, you may wish to check these terms to see how it may be used.',\n",
    "      'Cookies':'Cookies are files stored locally in your web browser containing identifiable information. This service may use them in ways you might not like.',\n",
    "      'Governance':'Your relationship with the service and the community: this is a broad spectrum but there may be concerning terms.',\n",
    "      'Guarantee':'Your guarantees may be limited.',\n",
    "      'Jurisdiction and governing laws':'Possible concern over the governing law for this service.',\n",
    "      'Law and government requests':'This service may not behave favourably or with transparency towards you, if government requests are received.',\n",
    "      'Logs':'The service may keep a significant record of your activity, or be less-than-transparent about it.',\n",
    "      'Ownership':'The content and the data you generate on services online is usually subject to copyright law: you may wish to check the service has the same view',\n",
    "      'Personal Data':'Your personal data may be used in unexpected ways and you may not have control of it once given.',\n",
    "      'Right to leave the service':'It may be difficult to leave this service or delete your data.',\n",
    "      'Scope of the copyright licence':'The copyright license may be so broad that your content can be exploited by others without asking you',\n",
    "      'Suspension and Censorship':'The service may be suspended or your lawful content removed without warning or recourse.',\n",
    "      'User information':'Terms that may contain noteworthy information',\n",
    "      'Third Parties':'Third parties may be involved in operating the service or otherwise be in receipt of your data',\n",
    "      'User choice':'These terms may give you some choice, or an illusion of choice'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "TAG_RE = re.compile(r'<[^>][^>]+>')\n",
    "\n",
    "def remove_tags(text):\n",
    "    return TAG_RE.sub(' ', text)\n",
    "\n",
    "def key_terms(url):\n",
    "    response = requests.get(url)\n",
    "    doc = Document(response.text)\n",
    "    full_text = doc.summary(html_partial=True)\n",
    "    full_text = full_text.replace(r\"\\n\", \" \")\n",
    "    full_text = full_text.replace(r\"\\t\", \" \")\n",
    "    full_text = full_text.replace(r\"/\", \" \")\n",
    "    full_text = remove_tags(full_text)\n",
    "    term_list = full_text.split('<p>')\n",
    "    term_list_check = []\n",
    "    for i in term_list:\n",
    "        if len(i) > 50:\n",
    "            term_list_check.append(i)\n",
    "    term_frame = pd.DataFrame(term_list_check, columns = ['quoteText'])\n",
    "    term_frame['tokens'] = term_frame['quoteText'].apply(tokenizer.tokenize)\n",
    "    term_frame['lemmatized'] = term_frame.tokens.apply(lemmatize_block)\n",
    "    X_world_tfidf = tfidf.transform(term_frame['lemmatized'])\n",
    "#     lr_tfidf.fit(X_train_tfidf, y_train_topic)\n",
    "    world_preds = lr_tfidf.predict(X_world_tfidf)\n",
    "    world_topic = pd.DataFrame(world_preds, columns =['pred_topic'])\n",
    "    X_world_tfidf_class = tfidf_class.transform(term_frame['lemmatized'])\n",
    "#     sgdc_binary.fit(X_train_tfidf_class, y_train_class)\n",
    "    Y_world_pp = pd.DataFrame(sgdc_binary.predict_proba(X_world_tfidf_class), columns=['warning_pp','neutral_pp'])\n",
    "    scrape_results = pd.merge(term_frame, world_topic, left_index=True, right_index=True)\n",
    "    scrape_res_final = pd.merge(scrape_results, Y_world_pp, left_index=True, right_index=True)\n",
    "    res = scrape_res_final[scrape_res_final.warning_pp > 0.5].sort_values('neutral_pp')\n",
    "    noct = len(res)\n",
    "    res = res.head(10)\n",
    "    print(\"Thanks for using the Terms Classifier. The title of the analysed extract is:\")\n",
    "    print('\"'+doc.title()+'\"')\n",
    "    print()\n",
    "    topics_in_this_extract = []\n",
    "    for i in res['pred_topic']:\n",
    "        if i not in topics_in_this_extract:\n",
    "            topics_in_this_extract.append(i)\n",
    "    if len(topics_in_this_extract) == 0:\n",
    "        print('No concerning terms were found in this extract!')\n",
    "    else:\n",
    "        print(\"The terms have been analysed! You might want to pay attention to the following:\")\n",
    "        print()\n",
    "        for i in topics_in_this_extract:\n",
    "            topic = res[res['pred_topic'] == i]\n",
    "            print(i)\n",
    "            print(dd[i])\n",
    "            count = 0\n",
    "            for j in topic.index:\n",
    "                count +=1\n",
    "                print()\n",
    "                print(count,'. ', topic.quoteText[j])\n",
    "                print()\n",
    "            print('---')\n",
    "            print()\n",
    "        if noct > 10:\n",
    "            print('There were an additional',noct-10,'concerning terms found in addition to those above.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Here to try the Classifier\n",
    "\n",
    "Choose a service from the list below, or use your own URL.\n",
    "Enter it between the parentheses of *key_terms* and **run** the code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "forghetti = 'https://www.forghetti.com/eng/terms-of-service'\n",
    "neko_atsume = 'http://nekoatsume.com/en/kiyaku.html'\n",
    "stardew_valley = 'https://www.stardewvalley.net/terms/'\n",
    "pinterest ='https://policy.pinterest.com/en-gb/terms-of-service'\n",
    "instagram = 'https://help.instagram.com/478745558852511/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a URL here: https://www.amazon.co.uk/gp/feature.html?docId=1000700003\n",
      "\n",
      "Thanks for using the Terms Classifier. The title of the analysed extract is:\n",
      "\"Amazon.co.uk: Terms and Conditions\"\n",
      "\n",
      "The terms have been analysed! You might want to pay attention to the following:\n",
      "\n",
      "Anonymity and Tracking\n",
      "The service may be tracking you in unexpected ways\n",
      "\n",
      "1 .  4. The promotional credit cannot to be used in conjunction with any other offer. Promotion credits may not be used on any existing orders.\n",
      " \n",
      "\n",
      "\n",
      "2 .  5. If you cancel your order for a Qualifying Item, Offer ceases to apply and you will not receive your promotional credit. If you return a Qualifying Item, Amazon.co.uk reserves the right to withdraw your promotional credit and or charge you (using the payment method you used for the original order) for the value of the promotional credit or part thereof. \n",
      " \n",
      "\n",
      "\n",
      "3 .  3. Amazon.co.uk will use all reasonable endeavours to give you your promotional credit by the time stated in the promotion.  However, Amazon.co.uk accepts no responsibility or liability in the event that promotional credits are received later than this date. \n",
      " \n",
      "\n",
      "---\n",
      "\n",
      "Guarantee\n",
      "Your guarantees may be limited.\n",
      "\n",
      "1 .  6. In the event you return a Promotional Item, your refund will be for the amount paid for the returned item(s) less the value of the promotional credit used. \n",
      " \n",
      "\n",
      "---\n",
      "\n",
      "Business Transfers\n",
      "Your data might be a transferable business asset\n",
      "\n",
      "1 .  7. Each promotional credit has no cash redemption value and may not be transferred or assigned. \n",
      " \n",
      "\n",
      "---\n",
      "\n",
      "Governance\n",
      "Your relationship with the service and the community: this is a broad spectrum but there may be concerning terms.\n",
      "\n",
      "1 .  8. Postage and packing will be applied to each item in accordance with Amazon.co.uk's standard  delivery rates and policies .  \n",
      " \n",
      "\n",
      "\n",
      "2 .  2. Offer only applies to Qualifying Items and Promotional Items sold and dispatched by Amazon.co.uk at the website, www.amazon.co.uk.  It does not apply to purchases made from Amazon’s Warehouse Deals, from third-party sellers at Amazon.co.uk's Marketplace platform or at any of Amazon.co.uk's Trusted Partner sites, or from Amazon.com, Amazon.de, Amazon.fr, Amazon.it, Amazon.es, Amazon.co.jp, Amazon.cn or Amazon.ca.\n",
      " \n",
      "\n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "url = input('Enter a URL here: ')\n",
    "print()\n",
    "key_terms(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
